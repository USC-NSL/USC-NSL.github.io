<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NSL Lab - Rajrup</title>
  <meta name="description" content="Personal website of Rajrup">
  <link rel="stylesheet" href="https://usc-nsl.github.io/css/main.css">
  <link rel="canonical" href="https://usc-nsl.github.io/people/rajrup-ghosh/">
  <!-- <link rel="shortcut icon" type ="image/x-icon" href="https://usc-nsl.github.io/images/usc_favicon.png"> -->
  <link rel="shortcut icon" href="https://www.usc.edu/wp-content/themes/usc-homepage-2017/assets/images/favicon.ico?v=4.3.14" />
  <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css"> -->
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  <!-- Place this inside the <head> section -->
  <link rel="icon" type="image/png" href="/images/logopic/nsl_logo_3_Raj.png">



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
	  <a class="navbar-brand" href="https://usc-nsl.github.io/">
		<div class="logo-image">
			  <img src="/images/logopic/nsl_logo_3_Raj.png" height="44px" class="img-fluid">
		</div>
	  </a>  
    <a class="navbar-brand" href="https://usc-nsl.github.io/">NSL @ USC</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="https://usc-nsl.github.io/">Home</a></li>
		<li><a href="https://usc-nsl.github.io/people">Team</a></li>
		<!-- <li><a href="https://usc-nsl.github.io/vacancies">Vacancies</a></li> -->
		<li><a href="https://usc-nsl.github.io/publications">Publications</a></li>
		<!-- <li><a href="https://usc-nsl.github.io/research">Research</a></li> -->
		<!-- <li><a href="https://usc-nsl.github.io/pictures">(Pics)</a></li> -->
	  </ul>
	</div>
  </div>
</div>


    <div class="container-fluid">
      <div class="row">
        
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
	<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">


<div id="gridid" class="col-sm-12">
	<div class="row">
  <p><img src="https://usc-nsl.github.io/images/teampic/Rajrup/Rajrup-cover.jpg" class="img-responsive" width="22%" style="float: left"></p>
  <h1>Rajrup Ghosh</h1>
  <p><i style="font-size:20px">Ph.D. Candidate, <a href="https://nsl.usc.edu/" target="_blank" rel="noopener noreferrer">USC@NSL</a></i><br></p>

  <p><a href="mailto:rajrupgh@usc.edu" target="_blank"><i class="fa fa-envelope-square fa-3x"></i></a> 
   <a href="https://scholar.google.co.in/citations?user=9M6G_S0AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar-square ai-3x"></i></a> 
   <a href="https://usc-nsl.github.io/files/Rajrup_CV.pdf" target="_blank"><i class="ai ai-cv-square ai-3x"></i></a> 
   <a href="https://github.com/Rajrup" target="_blank" rel="noopener noreferrer"><i class="fa fa-github-square fa-3x"></i></a> 
   <a href="https://www.linkedin.com/in/rajrup-ghosh/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin-square fa-3x"></i></a> 
   <a href="https://twitter.com/rajrup_tweets" target="_blank" rel="noopener noreferrer"><i class="fa fa-twitter-square fa-3x"></i></a> 
  <!--  <a href="https://www.researchgate.net/profile/Rajrup-Ghosh" target="_blank"><i class="ai ai-researchgate-square ai-3x"></i></a>  --></p>
  <ul style="overflow: hidden">

  
	<li> (2019-2026) Ph.D. Candidate in Computer Science, University of Southern California (USC). </li>
  
	<li> (2017) M.Tech in Computational Science, Indian Institute of Science (IISc), Bangalore. </li>
  
	<li> (2015) B.E. in Computer Science, Indian Institute of Engineering Science and Technology (IIEST), Shibpur. </li>
  

  </ul>
  <p><br>
  Jump to <a href="#biography">Biography</a>, <a href="#publications">Publications</a>, <a href="#work-experience">Experiences</a>.</p>
</div>

<h2 id="biography">Biography</h2>

<p>I am a Ph.D. student in <a href="http://nsl.usc.edu/" target="_blank" rel="noopener noreferrer">Networked System Lab (NSL)</a> at <a href="http://www.usc.edu" target="_blank" rel="noopener noreferrer">University of Southern California</a>. I am fortunate to be advised by <a href="https://govindan.usc.edu/" target="_blank" rel="noopener noreferrer">Prof. Ramesh Govindan</a>. My primary research interests are in areas of <b>Volumetric Video</b>, <b>AR/VR Streaming</b>, <b>Edge+Cloud Computing</b> and <b>Systems for ML</b>.</p>
<p>Prior to joining USC, I completed my Masters in Computational Science at the <a href="http://cds.iisc.ac.in" target="_blank" rel="noopener noreferrer">Department of Computational and Data Sciences (CDS)</a>, <a href="https://www.iisc.ac.in" target="_blank" rel="noopener noreferrer">Indian Institute of Science (IISc), Bangalore</a>. I was advised by <a href="http://cds.iisc.ac.in/faculty/simmhan" target="_blank" rel="noopener noreferrer">Prof. Yogesh Simmhan</a> at <a href="https://dream-lab.in/" target="_blank" rel="noopener noreferrer">DREAM:Lab</a>.</p>

<p style="font-size: 1.4em; background-color: #ffebcd;"><b>Looking for Postdoctoral position starting Summer/Fall 2026. Please reach out if interested!</b></p>

<h2 id="work-experience">Work Experience</h2>

<p>
<em>Graduate Research Assistant (Aug 2019 - May 2026 (Exp.))</em><br>
Department of Computer Science, University of Southern California.<br>
</p>

<p>
<em>Research Intern (May 2022 - Aug 2022)</em><br>
Microsoft Research, Redmond, Washington.<br>
Mentors: <a title="Krishna's Website" href="https://www.microsoft.com/en-us/research/people/krchinta/" target="_blank" rel="noopener noreferrer">Krishna Chintalapudi</a>, <a title="Nijunj's Website" href="https://www.microsoft.com/en-us/research/people/nikunjr/" target="_blank" rel="noopener noreferrer">Nikunj Raghuvanshi</a>, <a title="Ranveer's Website" href="https://www.microsoft.com/en-us/research/people/ranveer/" target="_blank" rel="noopener noreferrer">Ranveer Chandra</a><br>
</p>

<p>
<em>Research Intern (June 2020 - Aug 2020)</em><br>
Microsoft Research, Redmond, Washington.<br>
Mentor: <a title="Krishna's Website" href="https://www.microsoft.com/en-us/research/people/krchinta/" target="_blank" rel="noopener noreferrer">Krishna Chintalapudi</a><br>
</p>

<p>
<em>Lead Engineer (Research) (July 2017 - July 2019)</em><br>
Samsung R&amp;D Institute India, Bangalore.<br>
</p>

<h2 id="teaching-experience">Teaching Experience</h2>

<p>
<em>Teaching Assistant at USC</em><br>
<b>Course:</b> CSCI 353 - Internetworking, Fall 2025, <b>Instructor:</b> <a href="https://govindan.usc.edu/" target="_blank" rel="noopener noreferrer">Prof. Ramesh Govindan</a>
</p>
<p>
<em>Teaching Assistant at USC</em><br>
<b>Course:</b> <a href="https://drive.google.com/file/d/1l2-jZawdV2FZ4Q1pmCkLtvplA6DK9DUa/view?usp=sharing" target="_blank" rel="noopener noreferrer">CS 551/651: Advanced Computer Networks, Spring 2022</a>, <b>Instructor:</b> <a href="https://govindan.usc.edu/" target="_blank" rel="noopener noreferrer">Prof. Ramesh Govindan</a>
</p>
<p>
<em>Guest Lecture at Princeton University</em>, <b>Topic:</b> Volumetric Video Streaming <a href="https://docs.google.com/presentation/d/1e-stQ41GS9mVqCpU4H306geXiYHGJCNg-MalHcSzmfM/edit?usp=sharing" target="_blank" rel="noopener noreferrer">[PPT]</a><br>
<b>Course:</b> <a href="https://ml-video-seminar.princeton.systems/" target="_blank" rel="noopener noreferrer">COS 598a: Machine Learning-Driven Video Systems, Spring 2022</a>, <b>Instructor:</b> <a href="https://www.cs.princeton.edu/~ravian/" target="_blank" rel="noopener noreferrer">Prof. Ravi Netravali</a>
</p>

<h2 id="awards">Awards</h2>

<ul style="overflow: hidden">
<li> CoNEXT 2025 Travel Grant Award. </li>
</ul>

<ul style="overflow: hidden">
<li> Graduate Student Annenberg Fellowship, 2019 - 2023. </li>
</ul>

<ul style="overflow: hidden">
<li> Received IISc Motorola Medal for Best CDS M.Tech. Thesis, 2015 - 2017. </li>
</ul>

<h2 id="publications">Publications</h2>

<div class="publications">

  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CoNEXT</abbr></div>

        <!-- Entry bib key -->
        <div id="livo" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">LiVo: Toward Bandwidth-adaptive Fully-Immersive Volumetric Video Conferencing</div>
          <!-- Author -->
          <div class="author">Rajrup Ghosh, Christina Suyong Shin, Lei Zhang, Muyang Ye, Tao Jin, Harsha V. Madhyastha, Ravi Netravali, Antonio Ortega, Sanjay Rao, Anthony Rowe, and Ramesh Govindan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Proc. ACM Netw.</em> Nov 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3768981" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
            <a href="https://github.com/USC-NSL/LiVo" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>Volumetric video allows users 6 degrees of freedom (6-DoF) in viewing continuously evolving scenes in 3D. Given broadband speeds today, volumetric video conferencing will soon be feasible. Even so, these scenes will need to be compressed, and compression will need to adapt to variations in bandwidth availability. Existing 3D compression techniques cannot adapt to bandwidth availability, are slow, and utilize bandwidth inefficiently, so they don’t scale well to large scene descriptions. LiVo achieves low-latency and large-scene two-way conferencing by maximally leveraging existing 2D video infrastructure, including compression standards, rate-adaptive codecs, and real-time transport protocols. To achieve high quality, LiVo must carefully compose scenes from multiple cameras into multiple streams, encode scene geometry in a novel way, adapt to and apportion available bandwidth dynamically between streams to ensure high reconstruction quality, and cull content outside the receiver’s field of view to reduce information sent into the network. These novel contributions enable LiVo to outperform the state-of-the-art by over 20% in objective quality. In a user study, LiVo achieves a mean opinion score of 4.1, while other approaches achieve significantly lower values.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACM MM</abbr></div>

        <!-- Entry bib key -->
        <div id="splatpose" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">SplatPose: On-Device Outdoor AR Pose Estimation Using Gaussian Splatting</div>
          <!-- Author -->
          <div class="author">Weiwu Pang, Rajrup Ghosh, Jiawei Yang, Ziyu Wei, Branden Leong, Yue Wang, and Ramesh Govindan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 33rd ACM International Conference on Multimedia</em> Nov 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3746027.3755709" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>Outdoor AR applications on mobile devices need accurate estimates for the pose of the device. In this paper, we develop SplatPose, a novel pose estimation technique that uses a data-driven 3D modeling technique called Gaussian Splatting. SplatPose uses a trained Gaussian Splatting model to render an image at an estimated device location, then matches features with the camera image to estimate pose. % Because this matching can be fast, SplatPose can, in theory, estimate pose entirely on a mobile device, while existing approaches cannot. To this end, SplatPose trains Gaussian Splatting models to be robust to appearance changes, thereby improving accuracy. It also incorporates a novel fast renderer to improve rendering speed. Using an AR pose estimation benchmark dataset, we show that SplatPose outperforms the state-of-the-art in terms of accuracy, and is up to an order of magnitude faster on a mobile device.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Ubicomp/IMWUT</abbr></div>

        <!-- Entry bib key -->
        <div id="aerotraj" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">AeroTraj: Trajectory Planning for Fast, and Accurate 3D Reconstruction Using a Drone-based LiDAR</div>
          <!-- Author -->
          <div class="author">Fawad Ahmad, Christina Suyong Shin, Rajrup Ghosh, John D’Ambrosio, Eugene Chai, Karthikeyan Sundaresan, and Ramesh Govindan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In </em> Sep 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3610911" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>This paper presents AeroTraj, a system that enables fast, accurate, and automated reconstruction of 3D models of large buildings using a drone-mounted LiDAR. LiDAR point clouds can be used directly to assemble 3D models if their positions are accurately determined. AeroTraj uses SLAM for this, but must ensure complete and accurate reconstruction while minimizing drone battery usage. Doing this requires balancing competing constraints: drone speed, height, and orientation. AeroTraj exploits building geometry in designing an optimal trajectory that incorporates these constraints. Even with an optimal trajectory, SLAM’s position error can drift over time, so AeroTraj tracks drift in-flight by offloading computations to the cloud and invokes a re-calibration procedure to minimize error. AeroTraj can reconstruct large structures with centimeter-level accuracy and with an average end-to-end latency below 250 ms, significantly outperforming the state of the art.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SoCC</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3472883.3486993" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Scrooge: A Cost-Effective Deep Learning Inference System</div>
          <!-- Author -->
          <div class="author">Yitao Hu, Rajrup Ghosh, and Ramesh Govindan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the ACM Symposium on Cloud Computing</em> Sep 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3472883.3486993" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>Advances in deep learning (DL) have prompted the development of cloud-hosted DL-based media applications that process video and audio streams in real-time. Such applications must satisfy throughput and latency objectives and adapt to novel types of dynamics, while incurring minimal cost. Scrooge, a system that provides media applications as a service, achieves these objectives by packing computations efficiently into GPU-equipped cloud VMs, using an optimization formulation to find the lowest cost VM allocations that meet the performance objectives, and rapidly reacting to variations in input complexity (e.g., changes in participants in a video). Experiments show that Scrooge can save serving cost by 16-32% (which translate to tens of thousands of dollars per year) relative to the state-of-the-art while achieving latency objectives for over 98% under dynamic workloads.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IoTDI</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3450268.3453521" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Rim: Offloading Inference to the Edge</div>
          <!-- Author -->
          <div class="author">Yitao Hu, Weiwu Pang, Xiaochen Liu, Rajrup Ghosh, Bongjun Ko, Wei-Han Lee, and Ramesh Govindan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the International Conference on Internet-of-Things Design and Implementation</em> Sep 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3450268.3453521" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>Video cameras are among the most ubiquitous sensors in the Internet-of-Things. Video and audio applications, such as cross-camera activity detection, avatar extraction or language translation will, in the future, offload processing to an edge cluster of GPUs. Rim is a management system for such clusters that satisfies throughput and latency requirements of these applications, while enabling high cluster utilization. It uses coarse-grained knowledge of application structure to profile throughput of applications on resources, then uses these profiles to place applications on cluster nodes to achieve these goals. It dynamically adapts placement to load and failures. Experiments show that on maximal workloads on a testbed, Rim can satisfy requirements of all applications, but competing approaches designed for low-latency GPU execution cannot.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">TCPS</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3140256" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Distributed Scheduling of Event Analytics across Edge and Cloud</div>
          <!-- Author -->
          <div class="author">Rajrup Ghosh, and Yogesh Simmhan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>ACM Trans. Cyber-Phys. Syst.</em> Jul 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3140256" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>Internet of Things (IoT) domains generate large volumes of high-velocity event streams from sensors, which need to be analyzed with low latency to drive decisions. Complex Event Processing (CEP) is a Big Data technique to enable such analytics and is traditionally performed on Cloud Virtual Machines (VM). Leveraging captive IoT edge resources in combination with Cloud VMs can offer better performance, flexibility, and monetary costs for CEP. Here, we formulate an optimization problem for energy-aware placement of CEP queries, composed as an analytics dataflow, across a collection of edge and Cloud resources, with the goal of minimizing the end-to-end latency for the dataflow. We propose a Genetic Algorithm (GA) meta-heuristic to solve this problem and compare it against a brute-force optimal algorithm (BF). We perform detailed real-world benchmarks on the compute, network, and energy capacity of edge and Cloud resources. These results are used to define a realistic and comprehensive simulation study that validates the BF and GA solutions for 45 diverse CEP dataflows, LAN and WAN setup, and different edge resource availability. We compare the GA and BF solutions against random and Cloud-only baselines for different configurations for a total of 1,764 simulation runs. Our study shows that GA is within 97% of the optimal BF solution that takes hours, maps dataflows with 4–50 queries in 1–26s, and only fails to offer a feasible solution ≤20% of the time.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CCGRID</abbr></div>

        <!-- Entry bib key -->
        <div id="8411011" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Adaptive Energy-Aware Scheduling of Dynamic Event Analytics Across Edge and Cloud Resources</div>
          <!-- Author -->
          <div class="author">Rajrup Ghosh, Siva Prakash Reddy Komma, and Yogesh Simmhan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)</em> May 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/8411011" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>The growing deployment of sensors as part of Internet of Things (IoT) is generating thousands of event streams. Complex Event Processing (CEP) queries offer a useful paradigm for rapid decision-making over such data sources. While often centralized in the Cloud, the deployment of capable edge devices on the field motivates the need for cooperative event analytics that span Edge and Cloud computing. Here, we identify a novel problem of query placement on edge and Cloud resources for dynamically arriving and departing analytic dataflows. We define this as an optimization problem to minimize the total makespan for all event analytics, while meeting energy and compute constraints of the resources. We propose 4 adaptive heuristics and 3 rebalancing strategies for such dynamic dataflows, and validate them using detailed simulations for 100 - 1000 edge devices and VMs. The results show that our heuristics offer O(seconds) planning time, give a valid and high quality solution in all cases, and reduce the number of query migrations. Furthermore, rebalance strategies when applied in these heuristics have significantly reduced the makespan by around 20 - 25%.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICAPR</abbr></div>

        <!-- Entry bib key -->
        <div id="7050676" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Exploring the self similar properties for monitoring of air quality information</div>
          <!-- Author -->
          <div class="author">Rajrup Ghosh, Dipanjan Ghosh, Sreemoyee Roy, and Abhik Mukherjee
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)</em> Jan 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/document/7050676" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Link</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract bibhidden">
            <p>Air quality information has assumed much importance over the years due to the increase in air pollution. One major hindrance in monitoring of air pollutants is the dearth of spatial availability of aerosol concentration measurements due to the cost involved in deployment of sensors. In this respect, self similarity analysis of data can be very useful. This work is based on standard grid based pollutant dispersion models in a simulated environment over different scales of grid size. The fractal dimension is considered as a scale invariant metric which gives an idea about the variation in pollutant concentration across different scales. A method is detailed for measuring the fractal dimension properties. Results indicate that it is possible to apply the dispersion models across different scales and also the air quality monitored in one region can be compared with other regions.</p>
          </div>
        </div>
      </div>
</li>
</ol>

</div>

</div>
      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<div class="col-sm-5 footer">
			
		  <p>© NSL Lab. Site made with <a href="https://jekyllrb.com" target="_blank" rel="noopener noreferrer">Jekyll</a></p>
              <p>We are part of the <a href="https://www.cs.usc.edu/" target="_blank" rel="noopener noreferrer">USC Viterbi Department of Computer Science</a> at the <a href="https://www.usc.edu/" target="_blank" rel="noopener noreferrer">University of Southern California</a>.</p>
		</div>
		<!-- <div class="col-sm-4">
		  Funding:<br />
		  - <a href="http://www.nwo.nl/en/research-and-results/programmes/Talent+Scheme">Vidi </a> and <a href='https://www.fom.nl/en/news/press-releases/2016/11/18/28634/'>Projectruimte</a> grants from <a href="http://www.nwo.nl">NWO</a> <br />
		  - <a href="https://www.universiteitleiden.nl/en/research/research-projects/science/frontiers-of-nanoscience-nanofront">Frontier of Nanosciences</a>, a gravity program from <a href="http://www.nwo.nl">NWO</a>
          - <a href='https://www.universiteitleiden.nl/en/news/2017/08/two-erc-grants-for-leiden-physics'>ERC starting grant</a>
		</div> -->
		
		<div class="col-sm-5 footer">
		  <b>Location:</b><br>
		  Ginsburg Hall (GCS), USC<br>
		  1031 Downey Way<br>
		  Los Angeles, CA 90089 (<a href="https://maps.app.goo.gl/Lewwi39ERreKH5NEA" target="_blank" rel="noopener noreferrer">Maps</a>)
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://usc-nsl.github.io/js/bootstrap.min.js"></script>


    <!-- Load Common JS -->
  <script src="/js/common.js"></script>


  </body>

</html>
